# -*- coding: utf-8 -*-
"""XAI_7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jRbWuggl-zFQGfIgQy7sOHfekrRU3Y7b
"""

# Commented out IPython magic to ensure Python compatibility.
# ì˜ˆì œ 7.1 í•©ì„±ê³± ì‹ ê²½ë§ì„ ì œì‘í•˜ê³  ì •í™•ë„ë¥¼ ì¶œë ¥í•˜ëŠ” ì½”ë“œ

import numpy as np
import pdb
import matplotlib.pyplot as plt
# %matplotlib inline
import tensorflow as tf
import tensorflow.contrib.slim as slim
from tensorflow.examples.tutorials.mnist import input_data

# extracting MNIST Dataset
mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)

# construct CNN
# set models tf.reset_default_graph()
x = tf.placeholder(tf.float32, [None, 784],name="x-in")
true_y = tf.placeholder(tf.float32, [None, 10],name="y-in")
keep_prob = tf.placeholder("float")
x_image = tf.reshape(x,[-1,28,28,1])

# laye

hidden_1 = slim.conv2d(x_image,5,[5,5]) # 28x28x5
pool_1 = slim.max_pool2d(hidden_1,[2,2]) # 14x14x5


# layer 2
hidden_2 = slim.conv2d(pool_1,5,[5,5]) # 14x14x5
pool_2 = slim.max_pool2d(hidden_2,[2,2]) # 7 x7x5


# layer 3
hidden_3 = slim.conv2d(pool_2,20,[5,5]) # 7x7x20
hidden_3 = slim.dropout(hidden_3,keep_prob) # 7x7x20

out_y = slim.fully_connected(slim.flatten(hidden_3), 10, activation_fn=tf.nn.softmax) # 10

cross_entropy = -tf.reduce_sum(true_y*tf.log(out_y))
correct_prediction = tf.equal(tf.argmax(out_y,1), tf.argmax(true_y,1))
print(out_y)
accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)

# learning
batchSize = 50
sess = tf.Session()
init = tf.global_variables_initializer()
sess.run(init)

for i in range(1000):
    batch = mnist.train.next_batch(batchSize)
    sess.run(train_step, feed_dict={x:batch[0],true_y:batch[1], keep_prob:0.5})
    if i % 100 == 0 and i != 0:
        trainAccuracy = sess.run(accuracy, feed_dict={x:batch[0], true_y:batch[1], keep_prob:1.0})

        #print("step %d, training accuracy %g"%(i, trainAccuracy))

# print Accuracy
#print('Accuracy: {:.2%}'.format(sess.run(accuracy, feed_dict={x: mnist.test.images, true_y: mnist.test.labels, keep_prob: 1.0})))

# ì˜ˆì œ 7.2 í•„ìš” ë³€ìˆ˜ 1, 2ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì½”ë“œ

layers = [hidden_1, pool_1, hidden_2, pool_2, hidden_3]
weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='.*weights.*')
biases = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='.*biases.*')

# ì˜ˆì œ 6.14(ì¤‘ë³µ) ê³„ì¸µë³„ í™œì„±í™” í•¨ìˆ˜ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ëŠ” ì½”ë“œ

def getActivations(layer, image):
    units = sess.run(layer, feed_dict={x: np.reshape(image, [1,784], order='F'), keep_prob:1.0})
    
    return units

# ì˜ˆì œ 7.4 LRPë¥¼ ìˆ˜í–‰í•  ì´ë¯¸ì§€ í•˜ë‚˜ë¥¼ ë¶€ë¥´ëŠ” ê³¼ì •

# show test image
idx = 4
pdb.set_trace()
imageToUse = mnist.test.images[idx]
plt.imshow(np.reshape(imageToUse,[28,28]), interpolation="nearest", cmap='gray')

# ì˜ˆì œ 7.5 í•©ì„±ê³± ì‹ ê²½ë§ì˜ ì€ë‹‰ ê³„ì¸µë§ˆë‹¤ í™œì„±í™” í•¨ìˆ˜ë¥¼ êµ¬í•˜ëŠ” ì½”ë“œ

# layers = [hidden_1, pool_1, hidden_2, pool_2, hidden_3]
activations = []
for layer in layers:
    activations.append(getActivations(layer, imageToUse))

# ì˜ˆì œ 7.6 í•©ì„±ê³± ì‹ ê²½ë§ì— ì´ë¯¸ì§€ë¥¼ ì…ë ¥í•˜ê³  out_y ì˜ˆì¸¡ ê²°ê³¼ë¥¼ êµ¬í•˜ëŠ” ì½”ë“œ

predict = sess.run(out_y, feed_dict={x: imageToUse.reshape([-1, 784]), keep_prob:1.0})[0]
idx = 0
for i in predict:
    print('[{}] {:.2%}'.format(idx, i))
    idx += 1

# ì˜ˆì œ 7.7 í•™ìŠµëœ í•©ì„±ê³± ì‹ ê²½ë§ìœ¼ë¡œë¶€í„° ë¶„ë¥˜ ê°€ëŠ¥ì„±ì´ ìµœëŒ€ê°€ ë˜ëŠ” ì¹´í…Œê³ ë¦¬ë¥¼ êµ¬í•˜ëŠ” ì½”ë“œ

f_x = max(predict)
print(f_x)

# ì˜ˆì œ 7.8 ì™„ì „ ì—°ê²° ì‹ ê²½ë§ì—ì„œ ì—­ì „íŒŒ ê¸°ìš¸ê¸°ë¥¼ êµ¬í•˜ëŠ” ìˆ˜ë„ ì½”ë“œ

# get FC layer gradient
def getGradient(activation, weight, bias):
    # forward pass
    W = tf.maximum(0., weight)
    b = tf.maximum(0., bias)
    z = tf.matmul(activation, w) + b

    # backward pass
    dX = tf.matmul(1/z, tf.transpose(W))
    return dX

#  ì˜ˆì œ 7.9 f_xë¡œë¶€í„° ë°”ë¡œ ì§ì „ ì€ë‹‰ì¸µì˜ íƒ€ë‹¹ì„± ì „íŒŒ ê°’ì„ êµ¬í•˜ëŠ” ì½”ë“œ

R4 = predict
R4.shape

# ì˜ˆì œ 7.9 FC ì—°ê²°ì—ì„œ LRPë¥¼ ìˆ˜í–‰í•˜ëŠ” ì½”ë“œ. ì˜ˆì œ 7.8ì˜ ì—­ì „íŒŒ ê¸°ìš¸ê¸°ë¥¼ êµ¬í•˜ëŠ” ì½”ë“œì— íƒ€ë‹¹ì„± ë³€ìˆ˜(relevance)ë¥¼ ê³±í•œë‹¤

def backprop_dense(activation, weight, bias, relevance):
    w = tf.maximum(0., weight)
    b = tf.maximum(0., bias)
    z = tf.matmul(activation, w) + b
    s = relevance / z
    c = tf.matmul(s, tf.transpose(w))
    return activation * c

# ì˜ˆì œ 7.10 ì˜ˆì œ 7.9ì—ì„œ ë§Œë“  LRP ê³µì‹ìœ¼ë¡œ ğ‘…3ë¥¼ êµ¬í•˜ëŠ” ì½”ë“œ

# layers = [hidden_1, pool_1, hidden_2, pool_2, hidden_3]
# (1, 28, 28, 5) (1, 14, 14, 5) (1, 7, 7, 20)
# activation, weights, biases
a = activations.pop()
w = weights.pop()
b = biases.pop()

print(a.shape)
print(w.shape)

R3 = backprop_dense(a.reshape(1,980), w, b, R4)

print(R3.shape)

# ì˜ˆì œ 7.11-(1) ì–¸í’€ë§ ì—°ì‚°ì—ì„œ LRPë¥¼ êµ¬í•˜ëŠ” ì½”ë“œ

from tensorflow.python.ops import gen_nn_ops

def backprop_pooling(activation, relevance):
    # kernel size, strides
    # if z is zero
    ksize = strides = [1, 2, 2, 1]
    z = tf.nn.max_pool(activation, ksize, strides, padding='SAME') + 1e-10
    s = relevance / z
    # input, argmax, argmax_mask
    c = gen_nn_ops._max_pool_grad(activation, z, s, ksize, strides, padding='SAME')
    return activation * c

# ì˜ˆì œ 7.11-(2) ì—­í•©ì„±ê³± ì—°ì‚°ì—ì„œ LRPë¥¼ êµ¬í•˜ëŠ” ì½”ë“œ

def backprop_conv(activation, weight, bias, relevance):
    strides = [1, 1, 1, 1]
    w = tf.maximum(0., weight)
    b = tf.maximum(0., bias)
    z = tf.nn.conv2d(activation, w, strides, padding='SAME')
    z = tf.nn.bias_add(z, b)
    s = relevance / z
    c = tf.nn.conv2d_backprop_input(tf.shape(activation), w, s, strides, padding='SAME')
    return activation * c

# ì˜ˆì œ 7.12 ğ‘…3 ë²¡í„°ë¡œë¶€í„° ì—­í•©ì„±ê³±ê³¼ ì–¸í’€ë§ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê³  ğ‘…2 ë²¡í„°ë¥¼ êµ¬í•˜ëŠ” ì½”ë“œ

# layers = [hidden_1, pool_1, hidden_2, pool_2]
# (1, 28, 28, 5)(1, 14, 14, 5)(1, 7, 7, 20)
# activation, weights, biases
w = weights.pop()
b = biases.pop()
p = activations.pop()
a = activations.pop()
print(p.shape)

# convolution backprop
R_conv = backprop_conv(p, w, b, tf.reshape(R3, [1, 7, 7, 20]))
print(R_conv.shape)
R2 = backprop_pooling(a, R_conv)
print(R2.shape)

# ì˜ˆì œ 7.11 ğ‘…2ì—ì„œ ì—­í•©ì„±ê³±ê³¼ ì–¸í’€ë§ ê³¼ì •ì„ ìˆ˜í–‰í•˜ê³  ğ‘…1 ë²¡í„°ë¥¼ êµ¬í•˜ëŠ” ì½”ë“œ

# layers = [hidden_1, pool_1]
# (1, 28, 28, 5)(1, 14, 14, 5)
# activation, weights, biases
w = weights.pop()
b = biases.pop()
p = activations.pop()
a = activations.pop()

# convolution backprop
R_conv = backprop_conv(p, w, b, R2)
print(R_conv.shape)

R1 = backprop_pooling(a, R_conv)
print(R1.shape)
print(np.sum(sess.run(R1)))

# ì˜ˆì œ 7.12 ğ‘…1 ê²°ê³¼ì—ì„œ ì›ë³¸ ì´ë¯¸ì§€ê¹Œì§€ LRPë¥¼ ìˆ˜í–‰í•˜ëŠ” ì½”ë“œ

img_activations = getActivations(x_image, imageToUse)
w = weights.pop()
b = biases.pop()
R0 = backprop_conv(img_activations, w, b, R1)
LRP_out = sess.run(R0)

# ì˜ˆì œ 7.13 ì›ë³¸ ì´ë¯¸ì§€ í˜•íƒœë¡œ íƒ€ë‹¹ì„± ì „íŒŒë¥¼ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¬¼ì„ ì´ë¯¸ì§€ í˜•íƒœë¡œ ì¶œë ¥í•˜ëŠ” ì½”ë“œ

plt.imshow(LRP_out.reshape(28, 28), interpolation="nearest", cmap=plt.cm.jet)

# ì˜ˆì œ 7.13 í•©ì„±ê³± ì‹ ê²½ë§ ì „ì²´ì— ëŒ€í•´ LRPë¥¼ ìˆ˜í–‰í•˜ëŠ” ì½”ë“œ

def getLRP(img):
    predict = sess.run(out_y, feed_dict={x: img.reshape([-1, 784]), keep_prob:1.0})[0]
    layers = [hidden_1, pool_1, hidden_2, pool_2, hidden_3]
    weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='.*weights.*')
    biases = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='.*biases.*')

    # layers = [hidden_1, pool_1, hidden_2, pool_2, hidden_3]
    activations = []
    for layer in layers:
        activations.append(getActivations(layer, img))

    # get f_x
    f_x = max(predict)

    # get R4
    predict[predict < 0] = 0
    R4 = predict

    # get R3
    a = activations.pop()
    w = weights.pop()
    b = biases.pop()
    R3 = backprop_dense(a.reshape(1,980), w, b, R4)

    # get R2
    w = weights.pop()
    b = biases.pop()
    p = activations.pop()
    a = activations.pop()
    R_conv = backprop_conv(p, w, b, tf.reshape(R3, [1, 7, 7, 20]))
    R2 = backprop_pooling(a, R_conv)

    # get R1
    w = weights.pop()
    b = biases.pop()
    p = activations.pop()
    a = activations.pop()
    R_conv = backprop_conv(p, w, b, R2)
    R1 = backprop_pooling(a, R_conv)

    # get R0
    img_activations = getActivations(x_image, img)
    w = weights.pop()
    b = biases.pop()
    R0 = backprop_conv(img_activations, w, b, R1)
    LRP_out = sess.run(R0)
    return LRP_out

# ì˜ˆì œ 7.13 í•©ì„±ê³± ì‹ ê²½ë§ ì „ì²´ì— ëŒ€í•´ LRPë¥¼ ìˆ˜í–‰í•˜ëŠ” ì½”ë“œ

# get MNIST dataset index dict
mnist_dict = {}
idx = 0
for i in mnist.test.labels:
    label = np.where(i == np.amax(i))[0][0]
    if mnist_dict.get(label):
        mnist_dict[label].append(idx)
    else:
        mnist_dict[label] = [idx]
    idx += 1

# get LRP
nums = []
for i in range(10):
    img_idx = mnist_dict[i][0]
    img = mnist.test.images[img_idx]
    lrp = getLRP(img)
    nums.append(lrp)

# plot images
plt.figure(figsize=(20,10))
for i in range(2):
    for j in range(5):
        idx = 5 * i + j
        plt.subplot(2, 5, idx + 1)
        plt.title('digit: {}'.format(idx))
        plt.imshow(nums[idx].reshape([28, 28]), cmap=plt.cm.jet)
        plt.colorbar(orientation='horizontal')
plt.tight_layout()
sess.close()